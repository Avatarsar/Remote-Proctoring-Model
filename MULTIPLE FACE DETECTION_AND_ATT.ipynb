{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94122d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\sarad\\anaconda3\\lib\\site-packages (0.10.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from mediapipe) (3.7.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from mediapipe) (2.0.0)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from mediapipe) (22.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from mediapipe) (1.23.5)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from mediapipe) (23.5.26)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from mediapipe) (4.8.0.76)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.0.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (9.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (4.25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (22.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "054feff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\users\\sarad\\anaconda3\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from SpeechRecognition) (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (1.26.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73715ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyaudio in c:\\users\\sarad\\anaconda3\\lib\\site-packages (0.2.13)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd916a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wave in c:\\users\\sarad\\anaconda3\\lib\\site-packages (0.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ca2ba8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\sarad\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: click in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: joblib in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sarad\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c2f597f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sarad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suspicious activity detected\n",
      "Converting Audio To Text and saving to file..... \n",
      "Speech Recognition could not understand audio\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import speech_recognition as sr\n",
    "import pyaudio\n",
    "import wave\n",
    "import threading\n",
    "import os\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "class Face:\n",
    "    def __init__(self):\n",
    "        self.bbox = None\n",
    "        self.img = None\n",
    "        self.name = None\n",
    "        self.distance = None\n",
    "        self.confidence = None\n",
    "        self.landmarks = None\n",
    "        self.mouth = None\n",
    "        self.head = None\n",
    "        self.eye = None\n",
    "        self.spoof = None\n",
    "        self.spoof_score = None\n",
    "\n",
    "def get_face(frame, bbox):\n",
    "    real_h, real_w, c = frame.shape\n",
    "    x, y, w, h = bbox\n",
    "    y1 = 0 if y < 0 else y\n",
    "    x1 = 0 if x < 0 else x\n",
    "    y2 = real_h if y1 + h > real_h else y + h\n",
    "    x2 = real_w if x1 + w > real_w else x + w\n",
    "    face = frame[y1:y2, x1:x2, :]\n",
    "    return face\n",
    "\n",
    "def detect_faces(frame, confidence=0.7):\n",
    "    faces = []\n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "    with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=confidence) as face_detector:\n",
    "        frame.flags.writeable = False\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        results = face_detector.process(frame)\n",
    "        frame.flags.writeable = True\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if results.detections:\n",
    "        for _, detection in enumerate(results.detections):\n",
    "            face = Face()\n",
    "            bbox = detection.location_data.relative_bounding_box\n",
    "            ih, iw, ic = frame.shape\n",
    "            bbox = (\n",
    "                int(bbox.xmin * iw),\n",
    "                int(bbox.ymin * ih),\n",
    "                int(bbox.width * iw),\n",
    "                int(bbox.height * ih),\n",
    "            )\n",
    "            face.bbox = bbox\n",
    "            face.confidence = detection.score\n",
    "            face.img = get_face(frame, face.bbox)\n",
    "            faces.append(face)\n",
    "\n",
    "    return faces\n",
    "\n",
    "def recorder():\n",
    "    def read_audio(stream, filename):\n",
    "        chunk = 1024\n",
    "        sample_format = pyaudio.paInt16\n",
    "        channels = 2\n",
    "        fs = 44100\n",
    "        seconds = 10\n",
    "        filename = filename\n",
    "        frames = []\n",
    "\n",
    "        for i in range(0, int(fs / chunk * seconds)):\n",
    "            data = stream.read(chunk)\n",
    "            frames.append(data)\n",
    "\n",
    "        wf = wave.open(filename, 'wb')\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(p.get_sample_size(sample_format))\n",
    "        wf.setframerate(fs)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "        wf.close()\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "\n",
    "    def convert(i):\n",
    "        if i >= 0:\n",
    "            sound = 'record' + str(i) + '.wav'\n",
    "            r = sr.Recognizer()\n",
    "\n",
    "            with sr.AudioFile(sound) as source:\n",
    "                r.adjust_for_ambient_noise(source)\n",
    "                print(\"Converting Audio To Text and saving to file..... \")\n",
    "                audio = r.listen(source)\n",
    "            try:\n",
    "                value = r.recognize_google(audio)\n",
    "                os.remove(sound)\n",
    "                if isinstance(value, bytes):\n",
    "                    result = u\"{}\".format(value).encode(\"utf-8\")\n",
    "                else:\n",
    "                    result = \"{}\".format(value)\n",
    "\n",
    "                with open(\"test.txt\", \"a\") as f:\n",
    "                    f.write(result)\n",
    "                    f.write(\" \")\n",
    "\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"Speech Recognition could not understand audio\")\n",
    "            except sr.RequestError as e:\n",
    "                print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "            except KeyboardInterrupt:\n",
    "                pass\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "    chunk = 1024\n",
    "    sample_format = pyaudio.paInt16\n",
    "    channels = 2\n",
    "    fs = 44100\n",
    "\n",
    "    def save_audios(i):\n",
    "        stream = p.open(format=sample_format, channels=channels, rate=fs, frames_per_buffer=chunk, input=True)\n",
    "        filename = 'record' + str(i) + '.wav'\n",
    "        read_audio(stream, filename)\n",
    "\n",
    "    flag = False\n",
    "    for i in range(100 // 50):\n",
    "        t1 = threading.Thread(target=save_audios, args=[i])\n",
    "        x = i - 1\n",
    "        t2 = threading.Thread(target=convert, args=[x])\n",
    "        t1.start()\n",
    "        t2.start()\n",
    "        t1.join()\n",
    "        t2.join()\n",
    "        if i == 2:\n",
    "            flag = True\n",
    "    if flag:\n",
    "        convert(i)\n",
    "        p.terminate()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        faces = detect_faces(frame)\n",
    "\n",
    "        if faces:\n",
    "            for face in faces:\n",
    "                bbox = face.bbox\n",
    "                cv2.rectangle(\n",
    "                    frame,\n",
    "                    (bbox[0], bbox[1]),\n",
    "                    (bbox[0] + bbox[2], bbox[1] + bbox[3]),\n",
    "                    (0, 255, 0),\n",
    "                    2,\n",
    "                )\n",
    "\n",
    "            if len(faces) > 1:\n",
    "                print(\"Suspicious activity detected\")\n",
    "                recorder()\n",
    "\n",
    "        else:\n",
    "            print(\"No faces detected\")\n",
    "\n",
    "        cv2.imshow(\"Webcam\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77b32f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
